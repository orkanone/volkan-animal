noSuchKeyException=Keine Ressource f\u00fcr Key {0} vorhanden
iconNotFound=Icon {0} nicht gefunden

# General
algorithmName=MapReduce Algorithmus
name=MapReduce

# Overview
descriptionParagraph1=MapReduce ist ein Modell, das f&uuml;r nebenl&auml;ufige Berechnungen verwendet wird. Das Verfahren wurde von Google zur Verarbeitung von gro&szlig;en Datenmengen entwickelt, sodass die Verarbeitung dieser parallel und verteilt durchgef&uuml;hrt werden kann.
descriptionParagraph2=In diesem Beispiel wird die generelle Funktionsweise vom MapReduce-Verfahren in Pseudocode anhand eines Wordcount Algorithmus gezeigt. Eine bekannte Implementierung des MapReduce-Verfahrens in Java ist Apache Hadoop.


# TableOfContents
intro=Einleitung
outro=Zusammenfassung

# Algorithm
step1=Schritt 1: Splitting
step2=Schritt 2: Mapping
step3=Schritt 3: Shuffling
step4=Schritt 4: Reducing

# Source Code
sourceComment1=Teile die einzelnen Linien des Dokuments (der Eingabe) auf
sourceComment2=Mappe jedes Wort auf ein Schlüssel-Wert-Paar, wobei Schlüssel
sourceComment3=das jeweilige Wort und Wert die Häufigkeit ist (hier immer 1)
sourceComment4=Erstelle eine Wortliste für jedes unterschiedlich
sourceComment5=vorkommende Wort (=>sammle gleiche Worte in einer Liste)
sourceComment6=Gibt es bereits eine Liste für dieses Wort?
sourceComment7=Erstelle eine neue Liste für dieses Wort
sourceComment8=Für jede Wortliste, die im "Shuffling" Schritt erstellt wurde:
sourceComment9=Reduziere auf ein Schlüssel-Wert-Paar, wobei Wert die gesamte Worthäufigkeit ist

# Introduction Slide 1
intro1=MapReduce ist ein von Google entwickeltes Modell für nebenläufige Berechnungen von großen Datensätzen.
intro2=Eine verbreitete Implementierung in Java ist Apache Hadoop.
intro3=Der Algorithmus besteht aus 4 Phasen:
intro4=Der Input wird in n (Anzahl der Zeilen) Chunks geteilt
intro5=Die Daten werden in eine Map übertragen: Key ist der String, Value ist die Anzahl (in diesem Schritt noch bei 1).
intro6=Daten werden anhand des Keys sortiert, sodass k (verschiedene Daten) Chunks entstehen.
intro7=Jeder Worker kann nun einen Chunk verarbeiten.
intro8=Die Values der jeweiligen Keys werden addiert und auf eine Map reduziert.
intro9=Im finalen Output haben wir nun k Key-Value Paare.

# Recap
recap=Zusammenfassung \u0028Ende des Algorithmus\u0029
outro1=Es wurde das MapReduce Modell am Beispiel eines WordCount-Algorithmus dargestellt.
outro2=Generell wird MapReduce für jegliche Form der verteilten Verarbeitung großer Datensätze verwendet.
outro3=Der Algorithmus hat den eingehenden Datensatz in 4 Phasen verarbeitet.
outro4=Dabei wurden die Daten reduziert, bis nur noch die unterschiedlich vorkommenden
outro5=Worte des Input Strings und deren jeweilige Anzahl übrig blieben.
outro6=Als Ausgabe erhalten wir folgendes Ergebnis:

#( = \u0028
#) = \u0029
#